{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this script is used to exercise the use of one hot encoding in categorical data analysis (here I did Linear Regression). I tried to use different approaches for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 77)\n",
      "0    2213.18\n",
      "1    1283.60\n",
      "2    3005.09\n",
      "3     939.85\n",
      "4    2763.85\n",
      "Name: loss, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ting\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ting\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2369: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     cont1     cont2     cont3     cont4     cont5     cont6     cont7  \\\n",
      "0   1  0.726300  0.245921  0.187583  0.789639  0.310061  0.718367  0.335060   \n",
      "1   2  0.330514  0.737068  0.592681  0.614134  0.885834  0.438917  0.436585   \n",
      "2   5  0.261841  0.358319  0.484196  0.236924  0.397069  0.289648  0.315545   \n",
      "\n",
      "     cont8    cont9     ...      cat116_269  cat116_270  cat116_271  \\\n",
      "0  0.30260  0.67135     ...             0.0         0.0         0.0   \n",
      "1  0.60087  0.35127     ...             0.0         0.0         0.0   \n",
      "2  0.27320  0.26076     ...             0.0         0.0         0.0   \n",
      "\n",
      "   cat116_272  cat116_273  cat116_274  cat116_275  cat116_276  cat116_277  \\\n",
      "0         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "1         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "2         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "   cat116_278  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "\n",
      "[3 rows x 960 columns]\n",
      "(12000,)\n",
      "(12000,)\n",
      "The accuracy is: [ 7332.948937]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# set working directory\n",
    "os.chdir(r\"H:\\Tutorial\\Kaggle Competitions\\AllState\")\n",
    "col_names = pd.read_csv('train.csv', nrows=1).columns\n",
    "#print(list(col_names[0:20]))\n",
    "\n",
    "# for exercise only\n",
    "train = pd.read_csv('train.csv', nrows=60000,\n",
    "                    usecols=list(col_names[0:10]) + list(col_names[65:]))\n",
    "# for real run, read everything instead!\n",
    "#train = pd.read_csv('train.csv')\n",
    "print(train.shape)\n",
    "\n",
    "train_cat_only = train.select_dtypes(include=[object])\n",
    "train_num_only = train.select_dtypes(exclude=[object])\n",
    "cat_cols = train_cat_only.columns.values\n",
    "#print(train_cat_only.head(3))\n",
    "#print(train_cat_only.tail(3))\n",
    "#print(cat_cols)\n",
    "\n",
    "# Get the categorical values into a 2D numpy array\n",
    "#train_cat_values = np.array(train[cat_cols])\n",
    "train_cat_only = np.array(train_cat_only)\n",
    "#print(train_cat_only)\n",
    "\n",
    "# convert categorical data to numerical. To do so, we first convert categorical\n",
    "# data to int array and then convert int array to one hot encoding binary data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# for the first column for later stacking\n",
    "le  = LabelEncoder()\n",
    "train_cat_to_num = le.fit_transform(train_cat_only[:,0])\n",
    "\n",
    "for idx in range(1, len(cat_cols)):\n",
    "    le = LabelEncoder()\n",
    "    train_cat_to_num = np.column_stack((train_cat_to_num, \n",
    "                                        le.fit_transform(train_cat_only[:,idx])))\n",
    "\n",
    "train_cat_to_num = train_cat_to_num.astype(np.float32)\n",
    "#print(train_cat_to_num[0:2,])\n",
    "\n",
    "# for one-hot coding\n",
    "ohe = OneHotEncoder()\n",
    "train_cat_to_num = ohe.fit_transform(train_cat_to_num)\n",
    "#print(ohe.n_values_)\n",
    "#print(ohe.feature_indices_)\n",
    "\n",
    "# now we need to create the expanded column headers to form a data.frame from np.array\n",
    "col_names = []\n",
    "for i in range(0, len(cat_cols)):\n",
    "    for j in range(0, ohe.n_values_[i]):\n",
    "        col_names.append(cat_cols[i] + '_' + str(j))        \n",
    "#print(col_names)\n",
    "train_cat_to_num_df = pd.DataFrame(train_cat_to_num.toarray(), columns=col_names)\n",
    "#print(train_cat_to_num_df.head(2))\n",
    "\n",
    "# now need to combine with the original numerical data\n",
    "# but we have to get the target 'loss' out, before combining\n",
    "target = train_num_only['loss']\n",
    "print(target.head())\n",
    "train_num_only.drop(['loss'], 1, inplace=True)\n",
    "train_num_only[col_names] = train_cat_to_num_df[col_names]\n",
    "print(train_num_only.head(3))\n",
    "\n",
    "# now do linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing, cross_validation\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X = train_num_only\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, target, test_size=0.2)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(y_test.shape)\n",
    "mae = mean_absolute_error(np.array(y_test), np.array(y_pred), multioutput='raw_values')\n",
    "#accuracy = clf.score(X_test, y_test)\n",
    "print(\"The accuracy is:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The previous method has to manually add the column names, which is not quite easy for some applications. Here I use a different approach!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 77)\n",
      "(6000, 61)\n",
      "(6000, 16)\n",
      "0    2213.18\n",
      "1    1283.60\n",
      "2    3005.09\n",
      "Name: loss, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ting\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 744)\n",
      "   cat73=A  cat111=C  cat74=A  cat6=A  cat66=A  cat69=A  cat3=A  cat84=C  \\\n",
      "0      1.0       1.0      1.0     1.0      1.0      1.0     1.0      1.0   \n",
      "1      1.0       0.0      1.0     1.0      1.0      1.0     1.0      1.0   \n",
      "2      1.0       0.0      1.0     1.0      1.0      1.0     1.0      1.0   \n",
      "\n",
      "   cat104=I  cat102=A    ...      cat116=AW  cat110=P  cat110=DO  cat116=KY  \\\n",
      "0       1.0       1.0    ...            0.0       0.0        0.0        0.0   \n",
      "1       0.0       1.0    ...            0.0       0.0        0.0        0.0   \n",
      "2       0.0       1.0    ...            0.0       0.0        0.0        0.0   \n",
      "\n",
      "   cat109=AV  cat110=CT  cat114=V  cat116=CA  cat116=MK  cat110=AJ  \n",
      "0        0.0        0.0       0.0        0.0        0.0        0.0  \n",
      "1        0.0        0.0       0.0        0.0        0.0        0.0  \n",
      "2        0.0        0.0       0.0        0.0        0.0        0.0  \n",
      "\n",
      "[3 rows x 744 columns]\n",
      "(6000, 744)\n",
      "(6000, 759)\n",
      "Mean Absolute Error is:  [  6.74967153e+15]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as py\n",
    "import os\n",
    "\n",
    "# set up working directory\n",
    "os.chdir(r\"H:\\Tutorial\\Kaggle Competitions\\AllState\")\n",
    "\n",
    "# read training dataset\n",
    "# if you read everything for final run, use\n",
    "#train = pd.read_csv('train.csv')\n",
    "\n",
    "# for exercise, use the following\n",
    "col_names = pd.read_csv('train.csv', nrows=1).columns\n",
    "train = pd.read_csv(\"train.csv\", nrows=6000, \n",
    "                    usecols=list(col_names[0:10]) + list(col_names[65:]))\n",
    "print(train.shape)\n",
    "\n",
    "# get all categorical data and all numerical data separately\n",
    "train_cat_only = train.select_dtypes(include=[object])\n",
    "train_num_only = train.select_dtypes(exclude=[object])\n",
    "print(train_cat_only.shape)\n",
    "print(train_num_only.shape)\n",
    "\n",
    "# get the target column from train_num_only and remove it from train_num_only after that\n",
    "target = train_num_only['loss']\n",
    "train_num_only.drop(['loss'], 1, inplace=True)\n",
    "print(target.head(3))\n",
    "\n",
    "# convert categorical data to one hot encoded array\n",
    "\n",
    "# Using DictVectorizer() will loose the column names, even though you could get it\n",
    "# back using feature_names_. The order is inline with the final results\n",
    "#train_cat_only_sorted = train_cat_only.reindex_axis(sorted(train_cat_only.columns), axis=1)\n",
    "#print(train_cat_only_sorted.head(3))\n",
    "#print(train_cat_only.head(3))\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dv = DictVectorizer(sort=False)\n",
    "train_cat_to_num = dv.fit_transform(train_cat_only_sorted.to_dict(\"records\")).toarray()\n",
    "print(train_cat_to_num.shape)\n",
    "#print(dv.feature_names_)\n",
    "\n",
    "# to order the column names if you use vocabulary_\n",
    "#import operator\n",
    "#voc = dv.vocabulary_\n",
    "#ordered_col_names = sorted(voc.items(), key=operator.itemgetter(1))\n",
    "#print(ordered_col_names)\n",
    "\n",
    "# as the feature_names_ contains the column names corresponding to the train_cat_to_num\n",
    "# we can re-build the dataframe for further anaysis\n",
    "train_cat_to_num_df = pd.DataFrame(train_cat_to_num, columns=list(dv.feature_names_))\n",
    "print(train_cat_to_num_df.head(3))\n",
    "\n",
    "# use pandas get_dummies() is the best way to do it and get all column names \n",
    "train_cat_to_num = pd.get_dummies(train_cat_only)\n",
    "cat_names = train_cat_to_num.columns.values\n",
    "print(train_cat_to_num.shape)\n",
    "#print(train_cat_to_num.head(3))\n",
    "#print(cat_names)\n",
    "\n",
    "# now combine both categorical data and numeric data\n",
    "X = train_num_only.copy()\n",
    "X[cat_names] = train_cat_to_num[cat_names]\n",
    "print(X.shape)\n",
    "\n",
    "# preprocessing and validation\n",
    "from sklearn import preprocessing, cross_validation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X = preprocessing.scale(X)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, target, test_size=0.2)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "mae = mean_absolute_error(y_pred, y_test,multioutput='raw_values')\n",
    "print(\"Mean Absolute Error is: \", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
