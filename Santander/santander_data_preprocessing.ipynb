{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "target_cols = ['ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1',\n",
    "               'ind_ctju_fin_ult1','ind_ctma_fin_ult1','ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1',\n",
    "               'ind_deme_fin_ult1','ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1',\n",
    "               'ind_plan_fin_ult1','ind_pres_fin_ult1','ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1',\n",
    "               'ind_viv_fin_ult1','ind_nomina_ult1','ind_nom_pens_ult1','ind_recibo_ult1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2195520 entries, 0 to 2195519\n",
      "Data columns (total 48 columns):\n",
      "fecha_dato               object\n",
      "ncodpers                 int64\n",
      "ind_empleado             object\n",
      "pais_residencia          object\n",
      "sexo                     object\n",
      "age                      object\n",
      "fecha_alta               object\n",
      "ind_nuevo                float64\n",
      "antiguedad               object\n",
      "indrel                   float64\n",
      "ult_fec_cli_1t           object\n",
      "indrel_1mes              object\n",
      "tiprel_1mes              object\n",
      "indresi                  object\n",
      "indext                   object\n",
      "conyuemp                 object\n",
      "canal_entrada            object\n",
      "indfall                  object\n",
      "tipodom                  float64\n",
      "cod_prov                 float64\n",
      "nomprov                  object\n",
      "ind_actividad_cliente    float64\n",
      "renta                    float64\n",
      "segmento                 object\n",
      "ind_ahor_fin_ult1        int64\n",
      "ind_aval_fin_ult1        int64\n",
      "ind_cco_fin_ult1         int64\n",
      "ind_cder_fin_ult1        int64\n",
      "ind_cno_fin_ult1         int64\n",
      "ind_ctju_fin_ult1        int64\n",
      "ind_ctma_fin_ult1        int64\n",
      "ind_ctop_fin_ult1        int64\n",
      "ind_ctpp_fin_ult1        int64\n",
      "ind_deco_fin_ult1        int64\n",
      "ind_deme_fin_ult1        int64\n",
      "ind_dela_fin_ult1        int64\n",
      "ind_ecue_fin_ult1        int64\n",
      "ind_fond_fin_ult1        int64\n",
      "ind_hip_fin_ult1         int64\n",
      "ind_plan_fin_ult1        int64\n",
      "ind_pres_fin_ult1        int64\n",
      "ind_reca_fin_ult1        int64\n",
      "ind_tjcr_fin_ult1        int64\n",
      "ind_valo_fin_ult1        int64\n",
      "ind_viv_fin_ult1         int64\n",
      "ind_nomina_ult1          float64\n",
      "ind_nom_pens_ult1        float64\n",
      "ind_recibo_ult1          int64\n",
      "dtypes: float64(8), int64(23), object(17)\n",
      "memory usage: 804.0+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 929615 entries, 0 to 929614\n",
      "Data columns (total 24 columns):\n",
      "fecha_dato               929615 non-null object\n",
      "ncodpers                 929615 non-null int64\n",
      "ind_empleado             929615 non-null object\n",
      "pais_residencia          929615 non-null object\n",
      "sexo                     929610 non-null object\n",
      "age                      929615 non-null int64\n",
      "fecha_alta               929615 non-null object\n",
      "ind_nuevo                929615 non-null int64\n",
      "antiguedad               929615 non-null int64\n",
      "indrel                   929615 non-null int64\n",
      "ult_fec_cli_1t           1683 non-null object\n",
      "indrel_1mes              929592 non-null float64\n",
      "tiprel_1mes              929592 non-null object\n",
      "indresi                  929615 non-null object\n",
      "indext                   929615 non-null object\n",
      "conyuemp                 104 non-null object\n",
      "canal_entrada            927534 non-null object\n",
      "indfall                  929615 non-null object\n",
      "tipodom                  929615 non-null int64\n",
      "cod_prov                 925619 non-null float64\n",
      "nomprov                  925619 non-null object\n",
      "ind_actividad_cliente    929615 non-null int64\n",
      "renta                    929615 non-null object\n",
      "segmento                 927367 non-null object\n",
      "dtypes: float64(2), int64(7), object(15)\n",
      "memory usage: 170.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# read data in\n",
    "train = pd.read_csv(\"filtered_train_dataset.csv\")\n",
    "test  = pd.read_csv(\"../../input/test_ver2.csv\")\n",
    "print(train.info(memory_usage=True))\n",
    "print(test.info(memory_usage=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'2016-05-28': 931453, '2015-06-28': 632110, '2015-05-28': 631957})\n",
      "Counter({'2016-06-28': 929615})\n",
      "(2195520, 48)\n",
      "(929615, 24)\n",
      "(2195520, 24)\n"
     ]
    }
   ],
   "source": [
    "# it seems that some columns have mixed dtype. We need to unify everything\n",
    "print(Counter(train.fecha_dato))\n",
    "print(Counter(test.fecha_dato))\n",
    "\n",
    "train_rows = train.shape[0]\n",
    "print(train.shape)\n",
    "test_rows = test.shape[0]\n",
    "print(test.shape)\n",
    "\n",
    "trainX = train.iloc[:,:24]\n",
    "trainY = train.iloc[:,24:]\n",
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape is  (3125135, 24)\n"
     ]
    }
   ],
   "source": [
    "# combine train and test dataset together for preprocessing and cleaning\n",
    "combined = pd.concat([trainX, test], axis=0)\n",
    "print(\"The shape is \", combined.shape)\n",
    "\n",
    "# the dtype of some columns are not right, correct them, however, you can't convert nan to int in pandas, so use float\n",
    "combined.age = pd.to_numeric(combined.age, errors='coerce')\n",
    "combined.renta = pd.to_numeric(combined.renta, errors='coerce')\n",
    "combined.antiguedad = pd.to_numeric(combined.antiguedad, errors='coerce')\n",
    "combined.indrel_1mes = pd.to_numeric(combined.indrel_1mes, errors='coerce')\n",
    "\n",
    "# the 'conyuemp' column is empty at 100000, so remove it\n",
    "#combined.drop('conyuemp', 1, inplace=True)\n",
    "\n",
    "# tipodom doesn't seem to be useful, so I am going to drop it\n",
    "#combined.drop('tipodom', 1, inplace=True)\n",
    "\n",
    "# As 99% of 'ult_fec_cli_1t' information missing, so I am going to drop it\n",
    "#combined.drop('ult_fec_cli_1t', 1, inplace=True)\n",
    "\n",
    "# as we have both cod_prov and nomprov, they represent the same thing. so drop nomprov\n",
    "combined.drop('nomprov', 1, inplace=True)\n",
    "\n",
    "# separate numeric from categorical data\n",
    "combined_num = combined.select_dtypes(exclude=['object'])\n",
    "combined_cat = combined.select_dtypes(include=['object'])\n",
    "\n",
    "del combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'1': 3115079, 'P': 9568, '3': 341, '2': 122, '4': 25})\n",
      "Counter({'N': 3117675, nan: 5458, 'B': 825, 'F': 589, 'A': 584, 'S': 4})\n",
      "Counter({'KHE': 927355, 'KAT': 741917, 'KFC': 694797, 'KHQ': 150044, 'KFA': 93653, 'KHM': 66967, 'KHK': 57330, 'KHN': 39470, 'KHD': 26483, 'RED': 19606, 'KAS': 19365, 'KAG': 16903, 'KAY': 14997, 'KAA': 14972, 'AAA': 14288, 'KAB': 14049, 'KAE': 11381, 'KCC': 11158, 'KHL': 10881, 'KBZ': 10426, 'KFD': 9859, 'KAI': 8453, 'KEY': 7900, 'KAW': 7706, 'KAR': 7254, 'KAZ': 7096, 'KAF': 6934, '007': 6323, '013': 6290, 'KCI': 5856, 'KAH': 5585, 'KAJ': 5284, 'KCH': 5268, 'KHF': 4637, 'KAQ': 3980, 'KHC': 3562, 'KAP': 3279, 'KHO': 3272, 'KAM': 2515, 'KAD': 2450, 'KFP': 2101, 'KGX': 2088, 'KEJ': 2006, 'KGV': 1990, 'KDR': 1782, 'KAC': 1749, 'KFT': 1731, 'KAL': 1659, 'KBO': 1620, 'KBH': 1583, 'KFG': 1514, 'KAO': 1466, 'KFS': 1430, 'KFJ': 1424, 'KES': 1342, 'KEW': 1294, 'KCG': 1239, 'KFF': 1216, 'KCB': 1161, 'KEN': 1084, 'KFU': 1062, 'KFN': 991, 'KBQ': 948, 'KCL': 928, 'KGY': 916, 'KFK': 852, 'KFL': 846, 'KBF': 813, 'KCM': 718, 'KCD': 714, 'KBU': 683, 'KED': 676, 'KEZ': 569, 'KEL': 562, 'KDU': 558, 'KFH': 542, 'KDM': 535, 'KEG': 428, 'KBR': 426, 'KDY': 414, 'KDS': 402, 'KBG': 394, 'KDO': 376, 'KDX': 362, 'KEH': 353, 'KCA': 338, 'KDC': 332, 'KAN': 313, 'KDT': 296, 'KBB': 286, 'KDQ': 252, 'KCN': 244, 'KBW': 241, 'KCU': 232, 'KEI': 218, 'KDP': 211, 'KCK': 210, 'KGW': 208, 'KBV': 197, 'KAK': 194, 'KFI': 192, 'KEV': 192, 'KEO': 190, 'KEA': 182, 'KDE': 175, 'KDW': 174, 'KHP': 170, 'KDF': 158, 'KBS': 152, 'KBY': 137, 'KBL': 126, 'KBM': 124, 'KEK': 120, 'KBJ': 118, 'KDZ': 112, 'KDD': 108, 'KDG': 98, 'KDV': 94, 'KCF': 90, 'KFM': 82, 'KFR': 82, 'KEB': 80, 'KDA': 80, 'KEF': 68, 'KCE': 68, 'KEU': 60, 'KAU': 58, 'KFE': 54, 'KEC': 52, 'KBD': 52, 'KCS': 52, '004': 50, 'KCJ': 50, 'KCV': 48, 'KCQ': 44, 'KDN': 44, 'KDH': 42, 'KCR': 42, 'KEE': 40, 'KCO': 38, 'KCP': 36, 'K00': 34, 'KBE': 34, 'KEQ': 32, 'KHS': 27, 'KAV': 24, 'KFB': 24, 'KBX': 24, 'KBP': 20, 'KCT': 20, 'KEM': 16, 'KFV': 14, 'KCX': 14, 'KHA': 12, 'KBN': 12, 'KGU': 6, 'KGC': 6, 'KDB': 4, 'KGN': 4, 'KDI': 4, 'KHR': 2, 'KDL': 2, '025': 2})\n"
     ]
    }
   ],
   "source": [
    "### For AGE ###\n",
    "# for missing age value\n",
    "combined_num.age.fillna(39, inplace=True)\n",
    "\n",
    "# replace all the age < 18 to ave of 18-30 and > 90 with ave of 30-90\n",
    "combined_num.loc[combined_num.age < 18, 'age'] = 23\n",
    "combined_num.loc[combined_num.age > 90, 'age'] = 50\n",
    "combined_num.age = combined_num.age.astype(int)\n",
    "\n",
    "#### for ind_nuevo (New customer)\n",
    "combined_num['ind_nuevo'].fillna(1.0, inplace=True)\n",
    "\n",
    "#### for antiguedad (antiquity or Seniority), use the 25 percentile, which is 23\n",
    "combined_num['antiguedad'].fillna(23, inplace=True)\n",
    "\n",
    "#### for 'indrel' column, which indicates\n",
    "# 1 (First/Primary), 99 (Primary customer during the month but not at the end of the month)\n",
    "# use the most common one which is 1\n",
    "combined_num['indrel'].fillna(1.0, inplace=True)\n",
    "\n",
    "#### for 'indrel_1mes' column\n",
    "# As suggested by @StephenSmith\n",
    "map_dict = { 1.0  : \"1\",\n",
    "            \"1.0\" : \"1\",\n",
    "            \"1\"   : \"1\",\n",
    "            \"3.0\" : \"3\",\n",
    "            \"P\"   : \"5\",\n",
    "            3.0   : \"3\",\n",
    "            2.0   : \"2\",\n",
    "            \"3\"   : \"3\",\n",
    "            \"2.0\" : \"2\",\n",
    "            4.0   : \"4\",\n",
    "            \"4\"   : \"4\",\n",
    "            \"2\"   : \"2\"}\n",
    "\n",
    "combined_num.indrel_1mes.fillna(\"P\",inplace=True)\n",
    "combined_num.indrel_1mes = combined_num.indrel_1mes.apply(lambda x: map_dict.get(x,x))\n",
    "combined_num.indrel_1mes = combined_num.indrel_1mes.astype(\"category\")\n",
    "print(Counter(combined_num.indrel_1mes))\n",
    "\n",
    "#### for tipodom: (Addres type. 1, primary address), \n",
    "# since this one doesn't provide any useful information, so will drop it eventually\n",
    "combined_num['tipodom'].fillna(1.0, inplace=True)\n",
    "\n",
    "#### for cod_prov: provincial code for the address, use '0' for the unknown code\n",
    "combined_num['cod_prov'].fillna(0, inplace=True)\n",
    "\n",
    "#### ind_actividad_cliente  (Ind_activity customer), use '2.0 for the unknown value\n",
    "combined_num['ind_actividad_cliente'].fillna(2.0, inplace=True)\n",
    "\n",
    "#### renta (rental), assign them region by region\n",
    "rental_dict = {0.0: 190864.28134387353, 1.0: 116454.21824999999, 2.0: 83059.639880275121, 3.0: 87347.808423990966, \n",
    "               4.0: 85374.23584159567, 5.0: 76816.518459868807, 6.0: 72176.18582748514, 7.0: 171995.86848114064, \n",
    "               8.0: 164672.39357774809, 9.0: 97878.796620592184, 10.0: 75372.170251322314, 11.0: 98648.098741735899, \n",
    "               12.0: 79174.239231086744, 13.0: 69896.499221334176, 14.0: 85622.935385531295, 15.0: 112788.86299594035, \n",
    "               16.0: 69949.635891681086, 17.0: 144340.73909940803, 18.0: 96553.136598167126, 19.0: 95550.728265982965, \n",
    "               20.0: 139632.71175824184, 21.0: 76687.208433018008, 22.0: 89229.944358405774, 23.0: 77132.018859586417, \n",
    "               24.0: 93387.127306748385, 25.0: 81230.193312456133, 26.0: 99642.268904048149, 27.0: 76675.52248979923, \n",
    "               28.0: 178865.27951727214, 29.0: 121200.83724370257, 30.0: 79075.0041727278, 31.0: 105811.42276119406, \n",
    "               32.0: 83299.617043690712, 33.0: 101398.81625954412, 34.0: 92783.771758008908, 35.0: 100323.19958599037, \n",
    "               36.0: 113524.32363071061, 37.0: 105792.44947409695, 38.0: 102717.47302208183, 39.0: 121197.46123931887, \n",
    "               40.0: 98489.164981292226, 41.0: 117422.48873751337, 42.0: 88050.127969305482, 43.0: 104578.57903186574, \n",
    "               44.0: 87686.596356093884, 45.0: 80594.888512939171, 46.0: 89768.963794916985, 47.0: 101652.21498126048, \n",
    "               48.0: 110186.07268421052, 49.0: 83348.77014432376, 50.0: 110563.52870700191, 51.0: 199147.44231460703, \n",
    "               52.0: 149861.65298934001}\n",
    "\n",
    "for pcode in rental_dict.keys():\n",
    "    # fetch rows that are within the pcode and with 'renta' value is np.nan\n",
    "    idx = combined_num.loc[combined_num.cod_prov.isin([pcode]) & combined_num.renta.isnull(), 'renta'].index.tolist()\n",
    "    if idx:\n",
    "        #print(idx)\n",
    "        combined_num.ix[idx, 'renta'] = rental_dict[pcode]\n",
    "\n",
    "### For categorical columns ###\n",
    "\n",
    "### For fecha_alta (joined date)\n",
    "# Some entries don't have the date they joined the company. Just give them something in the middle of the pack\n",
    "combined_cat.loc[combined_cat.fecha_alta.isnull(),\"fecha_alta\"] = '2011-08-31'\n",
    "\n",
    "#### For conyuemp, assigned an unknown value\n",
    "combined_cat['conyuemp'].fillna('U', inplace=True)\n",
    "\n",
    "#### For ind_empleado (employed or employment), I will assign the most common one 'N'\n",
    "print(Counter(combined_cat.ind_empleado))\n",
    "combined_cat.loc[combined_cat.ind_empleado.isnull(), 'ind_empleado'] = 'N'\n",
    "\n",
    "#### For pais_residencia (Country of residency), use the most common one: 'ES'\n",
    "combined_cat.loc[combined_cat.pais_residencia.isnull(), 'pais_residencia'] = 'ES'\n",
    "\n",
    "#### For sexo, use unknown category\n",
    "combined_cat.loc[combined_cat.sexo.isnull(), 'sexo'] = 'U'\n",
    "\n",
    "#### for ult_fec_cli_1t\n",
    "combined_cat.loc[combined_cat.ult_fec_cli_1t.isnull(), 'ult_fec_cli_1t'] = '2011-01-11'\n",
    "\n",
    "#### For indfall, use the most common one\n",
    "combined_cat.loc[combined_cat.indfall.isnull(), 'indfall'] = 'N'\n",
    "\n",
    "#### For tiprel_1mes, use an unknown category\n",
    "combined_cat.loc[combined_cat.tiprel_1mes.isnull(), 'tiprel_1mes'] = 'U'\n",
    "\n",
    "#### For indresi, use the most common one\n",
    "combined_cat.loc[combined_cat.indresi.isnull(), 'indresi'] = 'S'\n",
    "\n",
    "#### For indext, use the most common one\n",
    "combined_cat.loc[combined_cat.indext.isnull(), 'indext'] = 'N'\n",
    "\n",
    "#### For canal_entrada (input channel), use an unknown one\n",
    "combined_cat.loc[combined_cat.canal_entrada.isnull(), 'canal_entrada'] = 'AAA'\n",
    "print(Counter(combined_cat.canal_entrada))\n",
    "\n",
    "#### For segmento (segment), use the unknown one\n",
    "combined_cat.loc[combined_cat.segmento.isnull(), 'segmento'] = '04 - unknown'\n",
    "\n",
    "### For trainY\n",
    "#### For ind_nomina_ult1 and ind_nom_pens_ult1, they only in training dataset. \n",
    "# Here I will assign them with the most common value, which is '0'\n",
    "trainY.loc[trainY.ind_nomina_ult1.isnull(), 'ind_nomina_ult1'] = 0\n",
    "trainY.loc[trainY.ind_nom_pens_ult1.isnull(), 'ind_nom_pens_ult1'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For categorical datan\n",
      " fecha_dato         False\n",
      "ind_empleado       False\n",
      "pais_residencia    False\n",
      "sexo               False\n",
      "fecha_alta         False\n",
      "ult_fec_cli_1t     False\n",
      "tiprel_1mes        False\n",
      "indresi            False\n",
      "indext             False\n",
      "conyuemp           False\n",
      "canal_entrada      False\n",
      "indfall            False\n",
      "segmento           False\n",
      "dtype: bool\n",
      "\n",
      "For numeric data:\n",
      " ncodpers                 False\n",
      "age                      False\n",
      "ind_nuevo                False\n",
      "antiguedad               False\n",
      "indrel                   False\n",
      "indrel_1mes              False\n",
      "tipodom                  False\n",
      "cod_prov                 False\n",
      "ind_actividad_cliente    False\n",
      "renta                    False\n",
      "dtype: bool\n",
      "\n",
      "For Y training data\n",
      " ind_ahor_fin_ult1    False\n",
      "ind_aval_fin_ult1    False\n",
      "ind_cco_fin_ult1     False\n",
      "ind_cder_fin_ult1    False\n",
      "ind_cno_fin_ult1     False\n",
      "ind_ctju_fin_ult1    False\n",
      "ind_ctma_fin_ult1    False\n",
      "ind_ctop_fin_ult1    False\n",
      "ind_ctpp_fin_ult1    False\n",
      "ind_deco_fin_ult1    False\n",
      "ind_deme_fin_ult1    False\n",
      "ind_dela_fin_ult1    False\n",
      "ind_ecue_fin_ult1    False\n",
      "ind_fond_fin_ult1    False\n",
      "ind_hip_fin_ult1     False\n",
      "ind_plan_fin_ult1    False\n",
      "ind_pres_fin_ult1    False\n",
      "ind_reca_fin_ult1    False\n",
      "ind_tjcr_fin_ult1    False\n",
      "ind_valo_fin_ult1    False\n",
      "ind_viv_fin_ult1     False\n",
      "ind_nomina_ult1      False\n",
      "ind_nom_pens_ult1    False\n",
      "ind_recibo_ult1      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(\"For categorical datan\\n\", combined_cat.isnull().any())\n",
    "print(\"\\nFor numeric data:\\n\", combined_num.isnull().any())\n",
    "print(\"\\nFor Y training data\\n\", trainY.isnull().any())\n",
    "#print(\"\\nshape of the combined data\\n\", combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now convert categorical data to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for  fecha_dato \n",
      " Counter({2: 931453, 3: 929615, 1: 632110, 0: 631957})\n",
      "for  ind_empleado \n",
      " Counter({0: 3123133, 2: 825, 3: 589, 1: 584, 4: 4})\n",
      "for  pais_residencia \n",
      " Counter({0: 3109793, 8: 1197, 11: 1127, 7: 1085, 9: 1075, 14: 852, 19: 824, 40: 686, 25: 678, 10: 598, 17: 548, 13: 535, 18: 509, 1: 471, 12: 353, 59: 351, 20: 331, 27: 331, 2: 230, 26: 209, 3: 180, 41: 178, 64: 175, 29: 138, 34: 137, 30: 130, 72: 120, 42: 116, 4: 113, 46: 112, 6: 104, 15: 98, 68: 98, 52: 96, 5: 94, 28: 92, 35: 80, 23: 64, 36: 56, 66: 56, 39: 52, 75: 52, 65: 48, 24: 44, 21: 34, 45: 32, 43: 30, 57: 30, 73: 28, 76: 28, 62: 26, 78: 26, 50: 24, 51: 24, 63: 24, 80: 24, 37: 22, 69: 22, 86: 22, 56: 20, 58: 20, 70: 20, 79: 20, 81: 20, 54: 18, 71: 18, 47: 16, 61: 16, 77: 16, 93: 16, 22: 14, 67: 14, 16: 12, 38: 12, 44: 12, 48: 12, 55: 12, 94: 12, 99: 12, 101: 12, 49: 10, 104: 10, 106: 10, 31: 8, 32: 8, 53: 8, 60: 8, 89: 8, 90: 8, 92: 8, 100: 8, 103: 8, 105: 6, 33: 4, 74: 4, 82: 4, 83: 4, 84: 4, 85: 4, 87: 4, 88: 4, 91: 4, 95: 4, 96: 4, 97: 4, 98: 4, 102: 4, 107: 4, 108: 4, 109: 4, 110: 4, 111: 4, 112: 4, 116: 3, 113: 2, 114: 2, 115: 2, 117: 2})\n",
      "for  sexo \n",
      " Counter({1: 1700964, 0: 1418697, 2: 5474})\n",
      "for  ult_fec_cli_1t \n",
      " Counter({0: 3120015, 54: 138, 53: 133, 31: 128, 43: 128, 36: 124, 19: 119, 26: 111, 44: 110, 37: 109, 5: 107, 1: 103, 49: 102, 57: 101, 28: 99, 39: 98, 33: 92, 18: 89, 21: 89, 32: 89, 10: 85, 25: 84, 30: 84, 52: 84, 64: 84, 23: 83, 34: 83, 17: 78, 22: 78, 38: 78, 56: 78, 58: 78, 63: 78, 3: 77, 42: 77, 48: 76, 40: 75, 47: 75, 62: 75, 9: 74, 20: 74, 41: 74, 27: 73, 46: 72, 15: 71, 2: 70, 59: 70, 29: 65, 45: 64, 4: 63, 61: 62, 11: 61, 24: 61, 55: 60, 51: 58, 14: 57, 35: 55, 8: 53, 13: 51, 7: 49, 50: 49, 16: 44, 6: 39, 12: 36, 60: 36})\n",
      "for  tiprel_1mes \n",
      " Counter({0: 1657118, 1: 1458083, 2: 9491, 3: 366, 4: 77})\n",
      "for  indresi \n",
      " Counter({0: 3109794, 1: 15341})\n",
      "for  indext \n",
      " Counter({0: 2976772, 1: 148363})\n",
      "for  conyuemp \n",
      " Counter({0: 3124740, 1: 391, 2: 4})\n",
      "for  canal_entrada \n",
      " Counter({0: 927355, 3: 741917, 6: 694797, 50: 150044, 2: 93653, 15: 66967, 5: 57330, 16: 39470, 1: 26483, 9: 19606, 74: 19365, 26: 16903, 65: 14997, 39: 14972, 8: 14288, 30: 14049, 29: 11381, 23: 11158, 11: 10881, 58: 10426, 36: 9859, 33: 8453, 94: 7900, 90: 7706, 28: 7254, 7: 7096, 21: 6934, 59: 6323, 24: 6290, 82: 5856, 25: 5585, 34: 5284, 64: 5268, 17: 4637, 38: 3980, 4: 3562, 44: 3279, 18: 3272, 112: 2515, 48: 2450, 35: 2101, 40: 2088, 86: 2006, 42: 1990, 61: 1782, 55: 1749, 93: 1731, 77: 1659, 67: 1620, 96: 1583, 27: 1514, 85: 1466, 43: 1430, 32: 1424, 72: 1342, 95: 1294, 53: 1239, 46: 1216, 75: 1161, 136: 1084, 37: 1062, 41: 991, 57: 948, 71: 928, 45: 916, 19: 852, 31: 846, 101: 813, 78: 718, 84: 714, 70: 683, 143: 676, 111: 569, 128: 562, 76: 558, 140: 542, 133: 535, 97: 428, 102: 426, 54: 414, 117: 402, 47: 394, 60: 376, 68: 362, 14: 353, 66: 338, 89: 332, 110: 313, 56: 296, 131: 286, 79: 252, 81: 244, 105: 241, 106: 232, 98: 218, 100: 211, 51: 210, 148: 208, 103: 197, 49: 194, 92: 192, 137: 192, 99: 190, 91: 182, 63: 175, 132: 174, 161: 170, 129: 158, 114: 152, 116: 137, 87: 126, 135: 124, 144: 120, 134: 118, 80: 112, 113: 108, 125: 98, 126: 94, 109: 90, 141: 82, 145: 82, 73: 80, 127: 80, 88: 68, 115: 68, 62: 60, 142: 58, 150: 54, 69: 52, 83: 52, 104: 52, 52: 50, 157: 50, 108: 48, 153: 44, 155: 44, 12: 42, 154: 42, 152: 40, 107: 38, 130: 36, 22: 34, 121: 34, 138: 32, 162: 27, 118: 24, 139: 24, 146: 24, 120: 20, 122: 20, 156: 16, 123: 14, 147: 14, 20: 12, 124: 12, 13: 6, 151: 6, 10: 4, 119: 4, 149: 4, 158: 2, 159: 2, 160: 2})\n",
      "for  indfall \n",
      " Counter({0: 3117231, 1: 7904})\n",
      "for  segmento \n",
      " Counter({1: 1826930, 0: 1147952, 3: 135493, 2: 14760})\n"
     ]
    }
   ],
   "source": [
    "for cat in combined_cat.columns:\n",
    "    combined_cat[cat], unique = pd.factorize(combined_cat[cat])\n",
    "    if cat != 'fecha_alta':\n",
    "        print(\"for \", cat, \"\\n\", Counter(combined_cat[cat]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join them together and then split them up according to training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined shape is:  (3125135, 23)  and the type is  <class 'pandas.core.frame.DataFrame'>\n",
      "Training X shape:  (2195520, 23)\n",
      "Testing X shape:  (929615, 23)\n",
      "Training Y shape:  (2195520, 24)\n",
      "(2195520, 47)\n"
     ]
    }
   ],
   "source": [
    "joined = pd.concat([combined_num, combined_cat], axis=1)\n",
    "print(\"joined shape is: \", joined.shape, \" and the type is \", type(joined))\n",
    "trainX = joined.iloc[:train_rows,:]\n",
    "testX  = joined.iloc[train_rows:,:]\n",
    "\n",
    "print(\"Training X shape: \", trainX.shape)\n",
    "print(\"Testing X shape: \", testX.shape)\n",
    "print(\"Training Y shape: \", trainY.shape)\n",
    "\n",
    "# now I need to combine trainX and trainY together\n",
    "combined = pd.concat([trainX, trainY], axis=1)\n",
    "print(combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here I am going to find out those people who have added/removed their services\n",
    "- Counter({'2016-05-28': 931453, '2015-06-28': 632110, '2015-05-28': 631957})\n",
    "- Counter({2: 931453, 1: 632110, 0: 631957})\n",
    "  - 0 ==> 2015-05-28;  1 ==> 2015-06-28;  2 ==> 2016-05-28;  3 ==> 2016-06-28\n",
    "- Counter({'2016-06-28': 929615})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 931453, 1: 632110, 0: 631957})\n",
      "(631957, 47)\n",
      "(632110, 47)\n",
      "2015-06-28 unique ones are:  (632110, 47)\n",
      "(931453, 47)\n",
      "Test size info is:  (929615, 23)\n",
      "2015-05-28 total customers:  631957\n",
      "2015-06-28 total customers:  632110\n",
      "Customers are in both 05-28 and 06-28 sets (2015):  628603\n",
      "Customers are only in 06-28 (2015):  3507\n",
      "(628603, 47)\n",
      "(628603, 47)\n",
      "2015-06-28 unique ones are (AFTER):  (3507, 47)\n"
     ]
    }
   ],
   "source": [
    "# for 2015\n",
    "print(Counter(combined.fecha_dato))\n",
    "train2015_05_28 = combined[combined.fecha_dato.isin([0])]\n",
    "train2015_05_28_unique = train2015_05_28.copy()\n",
    "print(train2015_05_28.shape)\n",
    "\n",
    "train2015_06_28 = combined[combined.fecha_dato.isin([1])]\n",
    "train2015_06_28_unique = train2015_06_28.copy()\n",
    "print(train2015_06_28.shape)\n",
    "print(\"2015-06-28 unique ones are: \", train2015_06_28_unique.shape)\n",
    "\n",
    "train2016_05_28 = combined[combined.fecha_dato.isin([2])]\n",
    "print(train2016_05_28.shape)\n",
    "\n",
    "print(\"Test size info is: \", testX[testX.fecha_dato.isin([3])].shape)\n",
    "\n",
    "# get unique customer IDs\n",
    "train55customers = set(train2015_05_28['ncodpers'])\n",
    "train56customers = set(train2015_06_28['ncodpers'])\n",
    "print(\"2015-05-28 total customers: \", len(train55customers))\n",
    "print(\"2015-06-28 total customers: \", len(train56customers))\n",
    "\n",
    "# find customers in both 2015-05-28 and 2015-06-28\n",
    "train_common_customers = train55customers & train56customers\n",
    "print(\"Customers are in both 05-28 and 06-28 sets (2015): \", len(train_common_customers))\n",
    "\n",
    "# new customers only in 2015-06-28\n",
    "train_unique_in_56 = train56customers - train55customers\n",
    "print(\"Customers are only in 06-28 (2015): \", len(train_unique_in_56))\n",
    "\n",
    "# old customers only in 2015-05-28 who dropped the services\n",
    "train_unique_in_55 = train55customers - train56customers\n",
    "print(\"Customers are only in 05-28 (2015)\", len(train_unique_in_55))\n",
    "\n",
    "train2015_05_28 = train2015_05_28[train2015_05_28.ncodpers.isin(train_common_customers)]\n",
    "train2015_06_28 = train2015_06_28[train2015_06_28.ncodpers.isin(train_common_customers)]\n",
    "print(train2015_05_28.shape)\n",
    "print(train2015_06_28.shape)\n",
    "\n",
    "# find the unique ones only in 2015-06-28\n",
    "train2015_06_28_unique = train2015_06_28_unique[train2015_06_28_unique.ncodpers.isin(train_unique_in_56)]\n",
    "print(\"2015-06-28 unique ones are (AFTER): \", train2015_06_28_unique.shape)\n",
    "\n",
    "# find the unique ones only in 2015-05-28\n",
    "train2015_05_28_unique = train2015_05_28_unique[train2015_05_28_unique.ncodpers.isin(train_unique_in_55)]\n",
    "print(\"2015-05-28 unique ones are (AFTER): \", train2015_05_28_unique.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files to disk for quick access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train2015_05_28.to_csv(\"train2015_05_28.csv\", index=False)\n",
    "#train2015_06_28.to_csv(\"train2015_06_28.csv\", index=False)\n",
    "#train2015_06_28_unique.to_csv(\"train2015_06_28_unique.csv\", index=False)\n",
    "#train2015_05_28_unique.to_csv(\"train2015_05_28_unique.csv\", index=False)\n",
    "#train2016_05_28.to_csv(\"train2016_05_28.csv\", index=False)\n",
    "#testX.to_csv(\"testX.csv\", index=False)\n",
    "\n",
    "# for changed ones:\n",
    "changed_ids = np.load(\"changed_ids_all.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(628603, 24)\n",
      "(628603, 24)\n",
      "          ind_ahor_fin_ult1  ind_aval_fin_ult1  ind_cco_fin_ult1  \\\n",
      "ncodpers                                                           \n",
      "15889                     0                  0                 1   \n",
      "\n",
      "          ind_cder_fin_ult1  ind_cno_fin_ult1  ind_ctju_fin_ult1  \\\n",
      "ncodpers                                                           \n",
      "15889                     0                 0                  0   \n",
      "\n",
      "          ind_ctma_fin_ult1  ind_ctop_fin_ult1  ind_ctpp_fin_ult1  \\\n",
      "ncodpers                                                            \n",
      "15889                     0                  0                  1   \n",
      "\n",
      "          ind_deco_fin_ult1       ...         ind_hip_fin_ult1  \\\n",
      "ncodpers                          ...                            \n",
      "15889                     0       ...                        0   \n",
      "\n",
      "          ind_plan_fin_ult1  ind_pres_fin_ult1  ind_reca_fin_ult1  \\\n",
      "ncodpers                                                            \n",
      "15889                     0                  0                  0   \n",
      "\n",
      "          ind_tjcr_fin_ult1  ind_valo_fin_ult1  ind_viv_fin_ult1  \\\n",
      "ncodpers                                                           \n",
      "15889                     1                  1                 0   \n",
      "\n",
      "          ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  \n",
      "ncodpers                                                       \n",
      "15889                 0.0                0.0                0  \n",
      "\n",
      "[1 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# need to find out those customers who changed services betweeen 2015-05-28 to 2015-06-28\n",
    "may_data  = train2015_05_28.sort_values(by='ncodpers').reset_index(drop=True).set_index('ncodpers')[target_cols]\n",
    "june_data = train2015_06_28.sort_values(by='ncodpers').reset_index(drop=True).set_index('ncodpers')[target_cols]\n",
    "print(may_data.shape)\n",
    "print(june_data.shape)\n",
    "print(june_data[june_data.index==15889])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33318, 25)\n",
      "Accounts have been changed:  33318\n",
      "Accounts have been changed ids \n",
      ":  [15906, 15925, 15927, 15964, 15982, 16026, 16043, 16056]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3c6de6644001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"changed_ids.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccounts_with_new_products\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_common_customers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not list"
     ]
    }
   ],
   "source": [
    "#differences = (june_data != may_data).any(1)\n",
    "differences = june_data - may_data\n",
    "differences[differences < 0] = 0\n",
    "#print(differences[differences < 0].head(2))\n",
    "\n",
    "differences[\"num_new_product\"] = differences.sum(axis=1)\n",
    "differences = differences.loc[differences.num_new_product > 0]\n",
    "print(differences.shape)\n",
    "#print(differences.head(2))\n",
    "\n",
    "accounts_with_new_products = differences.index\n",
    "print(\"Accounts have been changed: \", len(accounts_with_new_products))\n",
    "print(\"Accounts have been changed ids \\n: \", list(accounts_with_new_products)[2:10])\n",
    "\n",
    "np.save(\"changed_ids.txt\", accounts_with_new_products)\n",
    "\n",
    "print(len(list(train_common_customers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# need to find out those customers who changed services betweeen 2015-05-28 to 2015-06-28\n",
    "# to use this approach, I need to make sure their index are the same\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "\n",
    "changed_status_55 = []\n",
    "changed_status_56 = []\n",
    "train_common_customers = list(train_common_customers)\n",
    "\n",
    "for id in range(len(train_common_customers)):\n",
    "    customer = train_common_customers[id]\n",
    "    #print(customer)\n",
    "    \n",
    "    all_2015_05 = may_data[may_data.index == customer]\n",
    "    all_2015_06 = june_data[june_data.index == customer]\n",
    "    #print(all_2015_05.shape[0])\n",
    "\n",
    "    # for services changed\n",
    "    try:\n",
    "        assert_frame_equal(all_2015_05, all_2015_06)\n",
    "    except:\n",
    "        #changed_status_55 = pd.concat([changed_status_55, all_2015_05])\n",
    "        #changed_status_56 = pd.concat([changed_status_56, all_2015_06])\n",
    "        changed_status_55.append(customer)\n",
    "        changed_status_56.append(customer)\n",
    "        \n",
    "print(\"2015-05 total remaining: \", len(changed_status_55))\n",
    "print(\"2015-06 total remaining: \", len(changed_status_56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ind_aval_fin_ult1  ind_cco_fin_ult1  ind_cder_fin_ult1  \\\n",
      "34226                  0                 1                  0   \n",
      "\n",
      "       ind_cno_fin_ult1  ind_ctju_fin_ult1  ind_ctma_fin_ult1  \\\n",
      "34226                 0                  0                  0   \n",
      "\n",
      "       ind_ctop_fin_ult1  ind_ctpp_fin_ult1  ind_deco_fin_ult1  \\\n",
      "34226                  0                  0                  0   \n",
      "\n",
      "       ind_deme_fin_ult1       ...         ind_hip_fin_ult1  \\\n",
      "34226                  0       ...                        0   \n",
      "\n",
      "       ind_plan_fin_ult1  ind_pres_fin_ult1  ind_reca_fin_ult1  \\\n",
      "34226                  0                  0                  0   \n",
      "\n",
      "       ind_tjcr_fin_ult1  ind_valo_fin_ult1  ind_viv_fin_ult1  \\\n",
      "34226                  0                  0                 0   \n",
      "\n",
      "       ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  \n",
      "34226              0.0                0.0                0  \n",
      "\n",
      "[1 rows x 23 columns]\n",
      "(1, 47)\n"
     ]
    }
   ],
   "source": [
    "#print(train2015_05_28.iloc[:,24:].head(2))\n",
    "#print(train2015_05_28.head())\n",
    "print(train2015_05_28.loc[train2015_05_28.ncodpers == 1048576].iloc[:,24:])\n",
    "print(train2015_05_28.loc[train2015_05_28.ncodpers == 1061283].shape)\n",
    "#print(train2015_05_28.head().iloc[:,24:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
