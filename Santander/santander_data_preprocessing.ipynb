{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "target_cols = ['ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1',\n",
    "               'ind_ctju_fin_ult1','ind_ctma_fin_ult1','ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1',\n",
    "               'ind_deme_fin_ult1','ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1',\n",
    "               'ind_plan_fin_ult1','ind_pres_fin_ult1','ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1',\n",
    "               'ind_viv_fin_ult1','ind_nomina_ult1','ind_nom_pens_ult1','ind_recibo_ult1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3993880 entries, 0 to 3993879\n",
      "Data columns (total 48 columns):\n",
      "fecha_dato               object\n",
      "ncodpers                 int64\n",
      "ind_empleado             object\n",
      "pais_residencia          object\n",
      "sexo                     object\n",
      "age                      object\n",
      "fecha_alta               object\n",
      "ind_nuevo                float64\n",
      "antiguedad               object\n",
      "indrel                   float64\n",
      "ult_fec_cli_1t           object\n",
      "indrel_1mes              object\n",
      "tiprel_1mes              object\n",
      "indresi                  object\n",
      "indext                   object\n",
      "conyuemp                 object\n",
      "canal_entrada            object\n",
      "indfall                  object\n",
      "tipodom                  float64\n",
      "cod_prov                 float64\n",
      "nomprov                  object\n",
      "ind_actividad_cliente    float64\n",
      "renta                    float64\n",
      "segmento                 object\n",
      "ind_ahor_fin_ult1        int64\n",
      "ind_aval_fin_ult1        int64\n",
      "ind_cco_fin_ult1         int64\n",
      "ind_cder_fin_ult1        int64\n",
      "ind_cno_fin_ult1         int64\n",
      "ind_ctju_fin_ult1        int64\n",
      "ind_ctma_fin_ult1        int64\n",
      "ind_ctop_fin_ult1        int64\n",
      "ind_ctpp_fin_ult1        int64\n",
      "ind_deco_fin_ult1        int64\n",
      "ind_deme_fin_ult1        int64\n",
      "ind_dela_fin_ult1        int64\n",
      "ind_ecue_fin_ult1        int64\n",
      "ind_fond_fin_ult1        int64\n",
      "ind_hip_fin_ult1         int64\n",
      "ind_plan_fin_ult1        int64\n",
      "ind_pres_fin_ult1        int64\n",
      "ind_reca_fin_ult1        int64\n",
      "ind_tjcr_fin_ult1        int64\n",
      "ind_valo_fin_ult1        int64\n",
      "ind_viv_fin_ult1         int64\n",
      "ind_nomina_ult1          float64\n",
      "ind_nom_pens_ult1        float64\n",
      "ind_recibo_ult1          int64\n",
      "dtypes: float64(8), int64(23), object(17)\n",
      "memory usage: 1.4+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 929615 entries, 0 to 929614\n",
      "Data columns (total 24 columns):\n",
      "fecha_dato               929615 non-null object\n",
      "ncodpers                 929615 non-null int64\n",
      "ind_empleado             929615 non-null object\n",
      "pais_residencia          929615 non-null object\n",
      "sexo                     929610 non-null object\n",
      "age                      929615 non-null int64\n",
      "fecha_alta               929615 non-null object\n",
      "ind_nuevo                929615 non-null int64\n",
      "antiguedad               929615 non-null int64\n",
      "indrel                   929615 non-null int64\n",
      "ult_fec_cli_1t           1683 non-null object\n",
      "indrel_1mes              929592 non-null float64\n",
      "tiprel_1mes              929592 non-null object\n",
      "indresi                  929615 non-null object\n",
      "indext                   929615 non-null object\n",
      "conyuemp                 104 non-null object\n",
      "canal_entrada            927534 non-null object\n",
      "indfall                  929615 non-null object\n",
      "tipodom                  929615 non-null int64\n",
      "cod_prov                 925619 non-null float64\n",
      "nomprov                  925619 non-null object\n",
      "ind_actividad_cliente    929615 non-null int64\n",
      "renta                    929615 non-null object\n",
      "segmento                 927367 non-null object\n",
      "dtypes: float64(2), int64(7), object(15)\n",
      "memory usage: 170.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# read data in\n",
    "train = pd.read_csv(\"filtered_train_w_lag.csv\")\n",
    "test  = pd.read_csv(\"test_ver2.csv\")\n",
    "print(train.info(memory_usage=True))\n",
    "print(test.info(memory_usage=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'2016-05-28': 931453, '2015-11-28': 906109, '2015-10-28': 892251, '2015-06-28': 632110, '2015-05-28': 631957})\n",
      "Counter({'2016-06-28': 929615})\n",
      "(3993880, 48)\n",
      "(929615, 24)\n",
      "(3993880, 24)\n"
     ]
    }
   ],
   "source": [
    "# it seems that some columns have mixed dtype. We need to unify everything\n",
    "print(Counter(train.fecha_dato))\n",
    "print(Counter(test.fecha_dato))\n",
    "\n",
    "train_rows = train.shape[0]\n",
    "print(train.shape)\n",
    "test_rows = test.shape[0]\n",
    "print(test.shape)\n",
    "\n",
    "trainX = train.iloc[:,:24]\n",
    "trainY = train.iloc[:,24:]\n",
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape is  (4923495, 24)\n"
     ]
    }
   ],
   "source": [
    "# combine train and test dataset together for preprocessing and cleaning\n",
    "combined = pd.concat([trainX, test], axis=0)\n",
    "print(\"The shape is \", combined.shape)\n",
    "\n",
    "# the dtype of some columns are not right, correct them, however, you can't convert nan to int in pandas, so use float\n",
    "combined.age = pd.to_numeric(combined.age, errors='coerce')\n",
    "combined.renta = pd.to_numeric(combined.renta, errors='coerce')\n",
    "combined.antiguedad = pd.to_numeric(combined.antiguedad, errors='coerce')\n",
    "combined.indrel_1mes = pd.to_numeric(combined.indrel_1mes, errors='coerce')\n",
    "\n",
    "# the 'conyuemp' column is empty at 100000, so remove it\n",
    "#combined.drop('conyuemp', 1, inplace=True)\n",
    "\n",
    "# tipodom doesn't seem to be useful, so I am going to drop it\n",
    "#combined.drop('tipodom', 1, inplace=True)\n",
    "\n",
    "# As 99% of 'ult_fec_cli_1t' information missing, so I am going to drop it\n",
    "#combined.drop('ult_fec_cli_1t', 1, inplace=True)\n",
    "\n",
    "# as we have both cod_prov and nomprov, they represent the same thing. so drop nomprov\n",
    "combined.drop('nomprov', 1, inplace=True)\n",
    "\n",
    "# separate numeric from categorical data\n",
    "combined_num = combined.select_dtypes(exclude=['object'])\n",
    "combined_cat = combined.select_dtypes(include=['object'])\n",
    "\n",
    "del combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'1': 4871391, '5': 50353, '3': 1278, '2': 383, '4': 90})\n",
      "Counter({'N': 4914996, nan: 5458, 'B': 1262, 'F': 893, 'A': 880, 'S': 6})\n",
      "Counter({'KHE': 1433618, 'KAT': 1156496, 'KFC': 1098407, 'KHQ': 255253, 'KFA': 145262, 'KHK': 90674, 'KHM': 90368, 'AAA': 62617, 'KHN': 55324, 'KHD': 41370, 'KAS': 30582, 'RED': 28942, 'KAG': 26290, 'KAY': 23912, 'KAA': 23623, 'KAB': 22105, 'KAE': 17993, 'KCC': 17454, 'KHL': 16975, 'KBZ': 16466, 'KFD': 15788, 'KAI': 13349, 'KEY': 12458, 'KAW': 12146, 'KAR': 11575, 'KAZ': 11417, 'KAF': 10806, '007': 10463, '013': 9603, 'KCI': 9433, 'KAH': 8807, 'KAJ': 8642, 'KCH': 8571, 'KHF': 7410, 'KAQ': 6399, 'KHC': 5846, 'KAP': 5317, 'KHO': 4356, 'KAM': 4007, 'KAD': 3782, 'KFP': 3366, 'KGX': 3362, 'KEJ': 3288, 'KGV': 3172, 'KDR': 2858, 'KFT': 2855, 'KAC': 2727, 'KAL': 2691, 'KBO': 2623, 'KBH': 2553, 'KFG': 2412, 'KFS': 2388, 'KAO': 2372, 'KFJ': 2355, 'KES': 2088, 'KEW': 2014, 'KFF': 1967, 'KCG': 1913, 'KCB': 1837, 'KFU': 1750, 'KEN': 1742, 'KFN': 1607, 'KCL': 1486, 'KBQ': 1482, 'KGY': 1470, 'KFK': 1396, 'KFL': 1352, 'KBF': 1339, 'KCD': 1165, 'KCM': 1152, 'KBU': 1111, 'KED': 1066, 'KDU': 924, 'KFH': 920, 'KDM': 881, 'KEL': 876, 'KEZ': 871, 'KDY': 700, 'KDS': 688, 'KEG': 669, 'KBR': 664, 'KDO': 630, 'KDX': 618, 'KBG': 609, 'KEH': 547, 'KDC': 544, 'KCA': 544, 'KAN': 485, 'KBB': 462, 'KDT': 460, 'KBW': 405, 'KCN': 398, 'KDQ': 394, 'KCU': 386, 'KDP': 357, 'KGW': 354, 'KCK': 340, 'KEI': 334, 'KBV': 319, 'KFI': 314, 'KEA': 304, 'KHP': 304, 'KEO': 302, 'KEV': 298, 'KDE': 297, 'KAK': 296, 'KDW': 274, 'KDF': 258, 'KBS': 253, 'KBY': 229, 'KBL': 204, 'KBM': 196, 'KDD': 192, 'KEK': 192, 'KDZ': 190, 'KBJ': 184, 'KDG': 168, 'KDV': 152, 'KCF': 150, 'KDA': 134, 'KEB': 132, 'KFR': 132, 'KFM': 132, 'KEF': 118, 'KCE': 110, 'KEU': 94, 'KAU': 88, 'KFE': 88, 'KBD': 86, 'KCS': 84, 'KCV': 82, 'KEC': 82, 'KCJ': 76, '004': 76, 'KDN': 70, 'KCQ': 69, 'KDH': 68, 'KCR': 66, 'KCO': 64, 'KEE': 62, 'KCP': 56, 'K00': 54, 'KBE': 52, 'KEQ': 52, 'KCT': 38, 'KAV': 38, 'KFB': 38, 'KBX': 36, 'KBP': 30, 'KHS': 27, 'KEM': 24, 'KCX': 24, 'KFV': 24, 'KBN': 22, 'KHA': 18, 'KGU': 10, 'KGC': 10, 'KGN': 6, 'KDI': 6, 'KDB': 6, '025': 4, 'KDL': 4, 'KHR': 2})\n"
     ]
    }
   ],
   "source": [
    "### For AGE ###\n",
    "# for missing age value\n",
    "combined_num.age.fillna(39, inplace=True)\n",
    "\n",
    "# replace all the age < 18 to ave of 18-30 and > 90 with ave of 30-90\n",
    "combined_num.loc[combined_num.age < 18, 'age'] = 23\n",
    "combined_num.loc[combined_num.age > 90, 'age'] = 50\n",
    "combined_num.age = combined_num.age.astype(int)\n",
    "\n",
    "#### for ind_nuevo (New customer)\n",
    "combined_num['ind_nuevo'].fillna(1.0, inplace=True)\n",
    "\n",
    "#### for antiguedad (antiquity or Seniority), use the 25 percentile, which is 23\n",
    "combined_num['antiguedad'].fillna(23, inplace=True)\n",
    "\n",
    "#### for 'indrel' column, which indicates\n",
    "# 1 (First/Primary), 99 (Primary customer during the month but not at the end of the month)\n",
    "# use the most common one which is 1\n",
    "combined_num['indrel'].fillna(1.0, inplace=True)\n",
    "\n",
    "#### for 'indrel_1mes' column\n",
    "# As suggested by @StephenSmith\n",
    "map_dict = { 1.0  : \"1\",\n",
    "            \"1.0\" : \"1\",\n",
    "            \"1\"   : \"1\",\n",
    "            \"3.0\" : \"3\",\n",
    "            \"P\"   : \"5\",\n",
    "            3.0   : \"3\",\n",
    "            2.0   : \"2\",\n",
    "            \"3\"   : \"3\",\n",
    "            \"2.0\" : \"2\",\n",
    "            4.0   : \"4\",\n",
    "            \"4\"   : \"4\",\n",
    "            \"2\"   : \"2\"}\n",
    "\n",
    "combined_num.indrel_1mes.fillna(\"P\",inplace=True)\n",
    "combined_num.indrel_1mes = combined_num.indrel_1mes.apply(lambda x: map_dict.get(x,x))\n",
    "combined_num.indrel_1mes = combined_num.indrel_1mes.astype(\"category\")\n",
    "print(Counter(combined_num.indrel_1mes))\n",
    "\n",
    "#### for tipodom: (Addres type. 1, primary address), \n",
    "# since this one doesn't provide any useful information, so will drop it eventually\n",
    "combined_num['tipodom'].fillna(1.0, inplace=True)\n",
    "\n",
    "#### for cod_prov: provincial code for the address, use '0' for the unknown code\n",
    "combined_num['cod_prov'].fillna(0, inplace=True)\n",
    "\n",
    "#### ind_actividad_cliente  (Ind_activity customer), use '2.0 for the unknown value\n",
    "combined_num['ind_actividad_cliente'].fillna(2.0, inplace=True)\n",
    "\n",
    "#### renta (rental), assign them region by region\n",
    "rental_dict = {0.0: 190864.28134387353, 1.0: 116454.21824999999, 2.0: 83059.639880275121, 3.0: 87347.808423990966, \n",
    "               4.0: 85374.23584159567, 5.0: 76816.518459868807, 6.0: 72176.18582748514, 7.0: 171995.86848114064, \n",
    "               8.0: 164672.39357774809, 9.0: 97878.796620592184, 10.0: 75372.170251322314, 11.0: 98648.098741735899, \n",
    "               12.0: 79174.239231086744, 13.0: 69896.499221334176, 14.0: 85622.935385531295, 15.0: 112788.86299594035, \n",
    "               16.0: 69949.635891681086, 17.0: 144340.73909940803, 18.0: 96553.136598167126, 19.0: 95550.728265982965, \n",
    "               20.0: 139632.71175824184, 21.0: 76687.208433018008, 22.0: 89229.944358405774, 23.0: 77132.018859586417, \n",
    "               24.0: 93387.127306748385, 25.0: 81230.193312456133, 26.0: 99642.268904048149, 27.0: 76675.52248979923, \n",
    "               28.0: 178865.27951727214, 29.0: 121200.83724370257, 30.0: 79075.0041727278, 31.0: 105811.42276119406, \n",
    "               32.0: 83299.617043690712, 33.0: 101398.81625954412, 34.0: 92783.771758008908, 35.0: 100323.19958599037, \n",
    "               36.0: 113524.32363071061, 37.0: 105792.44947409695, 38.0: 102717.47302208183, 39.0: 121197.46123931887, \n",
    "               40.0: 98489.164981292226, 41.0: 117422.48873751337, 42.0: 88050.127969305482, 43.0: 104578.57903186574, \n",
    "               44.0: 87686.596356093884, 45.0: 80594.888512939171, 46.0: 89768.963794916985, 47.0: 101652.21498126048, \n",
    "               48.0: 110186.07268421052, 49.0: 83348.77014432376, 50.0: 110563.52870700191, 51.0: 199147.44231460703, \n",
    "               52.0: 149861.65298934001}\n",
    "\n",
    "for pcode in rental_dict.keys():\n",
    "    # fetch rows that are within the pcode and with 'renta' value is np.nan\n",
    "    idx = combined_num.loc[combined_num.cod_prov.isin([pcode]) & combined_num.renta.isnull(), 'renta'].index.tolist()\n",
    "    if idx:\n",
    "        #print(idx)\n",
    "        combined_num.ix[idx, 'renta'] = rental_dict[pcode]\n",
    "\n",
    "### For categorical columns ###\n",
    "\n",
    "### For fecha_alta (joined date)\n",
    "# Some entries don't have the date they joined the company. Just give them something in the middle of the pack\n",
    "combined_cat.loc[combined_cat.fecha_alta.isnull(),\"fecha_alta\"] = '2011-08-31'\n",
    "\n",
    "#### For conyuemp, assigned an unknown value\n",
    "combined_cat['conyuemp'].fillna('U', inplace=True)\n",
    "\n",
    "#### For ind_empleado (employed or employment), I will assign the most common one 'N'\n",
    "print(Counter(combined_cat.ind_empleado))\n",
    "combined_cat.loc[combined_cat.ind_empleado.isnull(), 'ind_empleado'] = 'N'\n",
    "\n",
    "#### For pais_residencia (Country of residency), use the most common one: 'ES'\n",
    "combined_cat.loc[combined_cat.pais_residencia.isnull(), 'pais_residencia'] = 'ES'\n",
    "\n",
    "#### For sexo, use unknown category\n",
    "combined_cat.loc[combined_cat.sexo.isnull(), 'sexo'] = 'U'\n",
    "\n",
    "#### for ult_fec_cli_1t\n",
    "combined_cat.loc[combined_cat.ult_fec_cli_1t.isnull(), 'ult_fec_cli_1t'] = '2011-01-11'\n",
    "\n",
    "#### For indfall, use the most common one\n",
    "combined_cat.loc[combined_cat.indfall.isnull(), 'indfall'] = 'N'\n",
    "\n",
    "#### For tiprel_1mes, use an unknown category\n",
    "combined_cat.loc[combined_cat.tiprel_1mes.isnull(), 'tiprel_1mes'] = 'U'\n",
    "\n",
    "#### For indresi, use the most common one\n",
    "combined_cat.loc[combined_cat.indresi.isnull(), 'indresi'] = 'S'\n",
    "\n",
    "#### For indext, use the most common one\n",
    "combined_cat.loc[combined_cat.indext.isnull(), 'indext'] = 'N'\n",
    "\n",
    "#### For canal_entrada (input channel), use an unknown one\n",
    "combined_cat.loc[combined_cat.canal_entrada.isnull(), 'canal_entrada'] = 'AAA'\n",
    "print(Counter(combined_cat.canal_entrada))\n",
    "\n",
    "#### For segmento (segment), use the unknown one\n",
    "combined_cat.loc[combined_cat.segmento.isnull(), 'segmento'] = '04 - unknown'\n",
    "\n",
    "### For trainY\n",
    "#### For ind_nomina_ult1 and ind_nom_pens_ult1, they only in training dataset. \n",
    "# Here I will assign them with the most common value, which is '0'\n",
    "trainY.loc[trainY.ind_nomina_ult1.isnull(), 'ind_nomina_ult1'] = 0\n",
    "trainY.loc[trainY.ind_nom_pens_ult1.isnull(), 'ind_nom_pens_ult1'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For categorical datan\n",
      " fecha_dato         False\n",
      "ind_empleado       False\n",
      "pais_residencia    False\n",
      "sexo               False\n",
      "fecha_alta         False\n",
      "ult_fec_cli_1t     False\n",
      "tiprel_1mes        False\n",
      "indresi            False\n",
      "indext             False\n",
      "conyuemp           False\n",
      "canal_entrada      False\n",
      "indfall            False\n",
      "segmento           False\n",
      "dtype: bool\n",
      "\n",
      "For numeric data:\n",
      " ncodpers                 False\n",
      "age                      False\n",
      "ind_nuevo                False\n",
      "antiguedad               False\n",
      "indrel                   False\n",
      "indrel_1mes              False\n",
      "tipodom                  False\n",
      "cod_prov                 False\n",
      "ind_actividad_cliente    False\n",
      "renta                    False\n",
      "dtype: bool\n",
      "\n",
      "For Y training data\n",
      " ind_ahor_fin_ult1    False\n",
      "ind_aval_fin_ult1    False\n",
      "ind_cco_fin_ult1     False\n",
      "ind_cder_fin_ult1    False\n",
      "ind_cno_fin_ult1     False\n",
      "ind_ctju_fin_ult1    False\n",
      "ind_ctma_fin_ult1    False\n",
      "ind_ctop_fin_ult1    False\n",
      "ind_ctpp_fin_ult1    False\n",
      "ind_deco_fin_ult1    False\n",
      "ind_deme_fin_ult1    False\n",
      "ind_dela_fin_ult1    False\n",
      "ind_ecue_fin_ult1    False\n",
      "ind_fond_fin_ult1    False\n",
      "ind_hip_fin_ult1     False\n",
      "ind_plan_fin_ult1    False\n",
      "ind_pres_fin_ult1    False\n",
      "ind_reca_fin_ult1    False\n",
      "ind_tjcr_fin_ult1    False\n",
      "ind_valo_fin_ult1    False\n",
      "ind_viv_fin_ult1     False\n",
      "ind_nomina_ult1      False\n",
      "ind_nom_pens_ult1    False\n",
      "ind_recibo_ult1      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(\"For categorical datan\\n\", combined_cat.isnull().any())\n",
    "print(\"\\nFor numeric data:\\n\", combined_num.isnull().any())\n",
    "print(\"\\nFor Y training data\\n\", trainY.isnull().any())\n",
    "#print(\"\\nshape of the combined data\\n\", combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now convert categorical data to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for  fecha_dato \n",
      " Counter({4: 931453, 5: 929615, 3: 906109, 2: 892251, 1: 632110, 0: 631957})\n",
      "for  ind_empleado \n",
      " Counter({0: 4920454, 2: 1262, 3: 893, 1: 880, 4: 6})\n",
      "for  pais_residencia \n",
      " Counter({0: 4900199, 8: 1824, 11: 1705, 7: 1639, 9: 1633, 14: 1298, 19: 1246, 25: 1041, 40: 1036, 10: 910, 17: 830, 13: 819, 18: 767, 1: 711, 12: 539, 59: 536, 20: 505, 27: 505, 2: 350, 26: 317, 3: 270, 41: 270, 64: 267, 29: 212, 34: 211, 30: 198, 72: 180, 42: 174, 4: 169, 46: 168, 6: 158, 15: 150, 68: 150, 52: 146, 5: 144, 28: 140, 35: 122, 23: 100, 36: 86, 66: 85, 75: 80, 39: 78, 65: 74, 24: 66, 21: 52, 45: 48, 43: 46, 57: 44, 73: 42, 76: 42, 62: 40, 78: 40, 50: 36, 51: 36, 63: 36, 80: 36, 37: 34, 69: 34, 86: 34, 79: 31, 58: 30, 70: 30, 81: 30, 54: 28, 56: 28, 47: 24, 61: 24, 71: 24, 77: 24, 93: 24, 22: 22, 67: 22, 16: 19, 38: 18, 44: 18, 48: 18, 55: 18, 94: 18, 99: 18, 101: 18, 49: 16, 104: 16, 106: 16, 31: 12, 32: 12, 53: 12, 60: 12, 89: 12, 90: 12, 92: 12, 100: 12, 103: 12, 105: 8, 33: 6, 74: 6, 82: 6, 83: 6, 84: 6, 85: 6, 87: 6, 88: 6, 91: 6, 95: 6, 96: 6, 97: 6, 98: 6, 102: 6, 107: 6, 108: 6, 109: 6, 110: 6, 111: 6, 112: 6, 114: 5, 113: 4, 115: 4, 116: 2, 117: 2})\n",
      "for  sexo \n",
      " Counter({1: 2676132, 0: 2241879, 2: 5484})\n",
      "for  ult_fec_cli_1t \n",
      " Counter({0: 4914559, 94: 138, 93: 133, 26: 131, 28: 129, 59: 128, 71: 128, 83: 128, 29: 125, 76: 124, 19: 119, 35: 115, 33: 113, 24: 112, 66: 111, 39: 110, 56: 110, 84: 110, 44: 109, 52: 109, 77: 109, 38: 108, 5: 107, 1: 103, 50: 103, 25: 102, 89: 102, 97: 101, 46: 100, 68: 99, 79: 98, 62: 96, 41: 94, 43: 94, 31: 93, 32: 93, 54: 93, 73: 92, 30: 91, 55: 91, 40: 90, 47: 90, 18: 89, 21: 89, 42: 89, 57: 89, 72: 89, 34: 88, 23: 87, 48: 86, 10: 85, 49: 85, 51: 84, 65: 84, 70: 84, 92: 84, 104: 84, 27: 83, 63: 83, 74: 83, 37: 82, 53: 80, 17: 78, 22: 78, 78: 78, 96: 78, 98: 78, 103: 78, 3: 77, 36: 77, 82: 77, 45: 76, 88: 76, 80: 75, 87: 75, 102: 75, 9: 74, 20: 74, 81: 74, 67: 73, 86: 72, 15: 71, 2: 70, 99: 70, 60: 66, 69: 65, 85: 64, 4: 63, 101: 62, 11: 61, 58: 61, 64: 61, 95: 60, 91: 58, 14: 57, 75: 55, 61: 54, 8: 53, 13: 51, 7: 49, 90: 49, 16: 44, 6: 39, 12: 36, 100: 36})\n",
      "for  tiprel_1mes \n",
      " Counter({0: 2633030, 1: 2238744, 2: 50097, 3: 1368, 4: 255, 5: 1})\n",
      "for  indresi \n",
      " Counter({0: 4900200, 1: 23295})\n",
      "for  indext \n",
      " Counter({0: 4688621, 1: 234874})\n",
      "for  conyuemp \n",
      " Counter({0: 4922872, 1: 617, 2: 6})\n",
      "for  canal_entrada \n",
      " Counter({0: 1433618, 3: 1156496, 6: 1098407, 50: 255253, 2: 145262, 5: 90674, 15: 90368, 8: 62617, 16: 55324, 1: 41370, 74: 30582, 9: 28942, 26: 26290, 65: 23912, 39: 23623, 30: 22105, 29: 17993, 23: 17454, 11: 16975, 58: 16466, 36: 15788, 33: 13349, 94: 12458, 90: 12146, 28: 11575, 7: 11417, 21: 10806, 59: 10463, 24: 9603, 82: 9433, 25: 8807, 34: 8642, 64: 8571, 17: 7410, 38: 6399, 4: 5846, 44: 5317, 18: 4356, 112: 4007, 48: 3782, 35: 3366, 40: 3362, 86: 3288, 42: 3172, 61: 2858, 93: 2855, 55: 2727, 77: 2691, 67: 2623, 96: 2553, 27: 2412, 43: 2388, 85: 2372, 32: 2355, 72: 2088, 95: 2014, 46: 1967, 53: 1913, 75: 1837, 37: 1750, 136: 1742, 41: 1607, 71: 1486, 57: 1482, 45: 1470, 19: 1396, 31: 1352, 101: 1339, 84: 1165, 78: 1152, 70: 1111, 143: 1066, 76: 924, 140: 920, 133: 881, 128: 876, 111: 871, 54: 700, 117: 688, 97: 669, 102: 664, 60: 630, 68: 618, 47: 609, 14: 547, 66: 544, 89: 544, 110: 485, 131: 462, 56: 460, 105: 405, 81: 398, 79: 394, 106: 386, 100: 357, 148: 354, 51: 340, 98: 334, 103: 319, 137: 314, 91: 304, 158: 304, 99: 302, 92: 298, 63: 297, 49: 296, 132: 274, 129: 258, 114: 253, 116: 229, 87: 204, 135: 196, 113: 192, 144: 192, 80: 190, 134: 184, 125: 168, 126: 152, 109: 150, 73: 134, 127: 132, 141: 132, 145: 132, 115: 118, 88: 110, 62: 94, 142: 88, 150: 88, 104: 86, 83: 84, 69: 82, 108: 82, 52: 76, 157: 76, 155: 70, 153: 69, 12: 68, 154: 66, 107: 64, 152: 62, 130: 56, 22: 54, 121: 52, 138: 52, 122: 38, 139: 38, 146: 38, 118: 36, 120: 30, 162: 27, 123: 24, 147: 24, 156: 24, 124: 22, 20: 18, 13: 10, 151: 10, 10: 6, 119: 6, 149: 6, 159: 4, 160: 4, 161: 2})\n",
      "for  indfall \n",
      " Counter({0: 4911001, 1: 12494})\n",
      "for  segmento \n",
      " Counter({1: 2865240, 0: 1791693, 3: 202919, 2: 63643})\n"
     ]
    }
   ],
   "source": [
    "for cat in combined_cat.columns:\n",
    "    combined_cat[cat], unique = pd.factorize(combined_cat[cat])\n",
    "    if cat != 'fecha_alta':\n",
    "        print(\"for \", cat, \"\\n\", Counter(combined_cat[cat]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join them together and then split them up according to training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined shape is:  (4923495, 23)  and the type is  <class 'pandas.core.frame.DataFrame'>\n",
      "Training X shape:  (3993880, 23)\n",
      "Testing X shape:  (929615, 23)\n",
      "Training Y shape:  (3993880, 24)\n",
      "(3993880, 47)\n"
     ]
    }
   ],
   "source": [
    "joined = pd.concat([combined_num, combined_cat], axis=1)\n",
    "print(\"joined shape is: \", joined.shape, \" and the type is \", type(joined))\n",
    "trainX = joined.iloc[:train_rows,:]\n",
    "testX  = joined.iloc[train_rows:,:]\n",
    "testX.to_csv(\"testX.csv\", index=False)\n",
    "\n",
    "print(\"Training X shape: \", trainX.shape)\n",
    "print(\"Testing X shape: \", testX.shape)\n",
    "print(\"Training Y shape: \", trainY.shape)\n",
    "\n",
    "# now I need to combine trainX and trainY together\n",
    "combined = pd.concat([trainX, trainY], axis=1)\n",
    "print(combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here I am going to find out those people who have added/removed their services\n",
    "- Counter({'2016-05-28': 931453, '2015-11-28': 906109, '2015-10-28': 892251, '2015-06-28': 632110, '2015-05-28': 631957})\n",
    "- Counter({4: 931453, 3: 906109, 2: 892251, 1: 632110, 0: 631957})\n",
    "  - 0 ==> 2015-05-28;  1 ==> 2015-06-28;  2 ==> 2015-10-28; 3 ==> 2015-11-28; 4 ==> 2016-05-28;  5 ==> 2016-06-28\n",
    "- Counter({'2016-06-28': 929615})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this function is used to calculate the union and the differences between two dataframes\n",
    "def get_union_difference(df1, df2, df2_copy):   # df2 is date behind df1\n",
    "    # get customer ids from each dataframe\n",
    "    df1_customers = set(df1['ncodpers'])\n",
    "    df2_customers = set(df2['ncodpers'])\n",
    "    print(\"entering the function call with customer ids count is \", len(df2_customers))\n",
    "    \n",
    "    # get the commone unions and then extract them out from each dataframe\n",
    "    common_ids = df1_customers & df2_customers\n",
    "    df1 = df1[df1.ncodpers.isin(common_ids)]\n",
    "    df2 = df2[df2.ncodpers.isin(common_ids)]\n",
    "    print(\"common shape is \", df2.shape)\n",
    "    \n",
    "    # now find the difference and extract the unique ones out\n",
    "    df2_unique_ids = df2_customers - df1_customers\n",
    "    df2_copy = df2_copy[df2_copy.ncodpers.isin(df2_unique_ids)]\n",
    "    print(\"unique shape is \", df2_copy.shape)\n",
    "    \n",
    "    return df1, df2, df2_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(631957, 47)\n",
      "(632110, 47)\n",
      "(892251, 47)\n",
      "(906109, 47)\n",
      "(931453, 47)\n",
      "entering the function call with customer ids count is  632110\n",
      "common shape is  (628603, 47)\n",
      "unique shape is  (3507, 47)\n"
     ]
    }
   ],
   "source": [
    "# for 2015\n",
    "train2015_05_28 = combined[combined.fecha_dato.isin([0])]\n",
    "train2015_05_28_lag = train2015_05_28.copy()\n",
    "print(train2015_05_28.shape)\n",
    "\n",
    "train2015_06_28 = combined[combined.fecha_dato.isin([1])]\n",
    "train2015_06_28_unique = train2015_06_28.copy()\n",
    "train2015_06_28_lag = train2015_06_28.copy()\n",
    "print(train2015_06_28.shape)\n",
    "\n",
    "train2015_10_28 = combined[combined.fecha_dato.isin([2])]\n",
    "train2015_10_28_lag = train2015_10_28.copy()\n",
    "print(train2015_10_28.shape)\n",
    "\n",
    "train2015_11_28 = combined[combined.fecha_dato.isin([3])]\n",
    "train2015_11_28_lag = train2015_11_28.copy()\n",
    "print(train2015_11_28.shape)\n",
    "\n",
    "train2016_05_28 = combined[combined.fecha_dato.isin([4])]\n",
    "train2016_05_28.to_csv(\"train2016_05_28.csv\", index=False)\n",
    "print(train2016_05_28.shape)\n",
    "\n",
    "# get union and differences between two dataframes\n",
    "train2015_05_28, train2015_06_28, train2015_06_28_unique = get_union_difference(train2015_05_28, train2015_06_28, train2015_06_28_unique)\n",
    "train2015_05_28.to_csv(\"train2015_05_28.csv\", index=False)\n",
    "train2015_06_28.to_csv(\"train2015_06_28.csv\", index=False)\n",
    "train2015_06_28_unique.to_csv(\"train2015_06_28_unique.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For lagging analysis\n",
    "- use 2015-06-28 against 2015-11-28 (5 month-lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering the function call with customer ids count is  906109\n",
      "common shape is  (626956, 47)\n",
      "unique shape is  (279153, 47)\n",
      "entering the function call with customer ids count is  892251\n",
      "common shape is  (626036, 47)\n",
      "unique shape is  (266215, 47)\n"
     ]
    }
   ],
   "source": [
    "# calculate the dataframe used for lagging time series\n",
    "\n",
    "# for 2015-06-28 to 2015-11-28\n",
    "train2015_11_28_lag_unique = train2015_11_28_lag.copy()\n",
    "train2015_06_28_lag, train2015_11_28_lag, train2015_11_28_lag_unique = get_union_difference(\n",
    "    train2015_06_28_lag, train2015_11_28_lag, train2015_11_28_lag_unique)\n",
    "train2015_06_28_lag.to_csv(\"train2015_06_28.csv\", index=False)\n",
    "train2015_11_28_lag.to_csv(\"train2015_11_28.csv\", index=False)\n",
    "train2015_11_28_lag_unique.to_csv(\"train2015_11_28_lag_unique.csv\", index=False)\n",
    "\n",
    "# for 2015=05-28 to 2015-10-28\n",
    "train2015_10_28_lag_unique = train2015_10_28_lag.copy()\n",
    "train2015_05_28_lag, train2015_10_28_lag, train2015_10_28_lag_unique = get_union_difference(\n",
    "    train2015_05_28_lag, train2015_10_28_lag, train2015_10_28_lag_unique)\n",
    "train2015_05_28_lag.to_csv(\"train2015_05_28_lag.csv\", index=False)\n",
    "train2015_10_28_lag.to_csv(\"train2015_10_28_lag.csv\", index=False)\n",
    "train2015_10_28_lag_unique.to_csv(\"train2015_10_28_lag_unique.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to find out whose services are changed in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customer_w_service_changed(df1, df2, num):\n",
    "    one = df1.sort_values(by='ncodpers').reset_index(drop=True).set_index('ncodpers')[target_cols]\n",
    "    two = df2.sort_values(by='ncodpers').reset_index(drop=True).set_index('ncodpers')[target_cols]\n",
    "    print(\"The final shape is \", one.shape)\n",
    "    \n",
    "    differences = two - one\n",
    "    differences[differences < 0] = 0   # reset to 0, so we only consider those with added services\n",
    "\n",
    "    differences[\"num_new_product\"] = differences.sum(axis=1)\n",
    "    differences = differences.loc[differences.num_new_product > 0]\n",
    "    print(differences.shape)\n",
    "    \n",
    "    accounts_with_new_products = differences.index   # because the index was reset to ncodpers\n",
    "    print(\"Accounts have been changed: \", len(accounts_with_new_products))\n",
    "\n",
    "    np.save(\"changed_ids\"+num, accounts_with_new_products)\n",
    "    return accounts_with_new_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final shape is  (628603, 24)\n",
      "(33318, 25)\n",
      "Accounts have been changed:  33318\n",
      "The final shape is  (626036, 24)\n",
      "(53655, 25)\n",
      "Accounts have been changed:  53655\n",
      "The final shape is  (626956, 24)\n",
      "(45006, 25)\n",
      "Accounts have been changed:  45006\n"
     ]
    }
   ],
   "source": [
    "changed_june = customer_w_service_changed(train2015_05_28, train2015_06_28, '0506')\n",
    "changed_oct  = customer_w_service_changed(train2015_05_28_lag, train2015_10_28_lag, '0510')\n",
    "changed_nov  = customer_w_service_changed(train2015_06_28_lag, train2015_11_28_lag, '0611')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed id length is:  51489  with  [1048830, 1048863, 1048902, 1048926, 1048957, 1049016]\n",
      "(51489, 47)\n",
      "(51489, 47)\n"
     ]
    }
   ],
   "source": [
    "# for changed ones:\n",
    "changed_ids = []\n",
    "with open(\"changed_ids_all.txt\", 'r') as f:\n",
    "    for i in f:\n",
    "        changed_ids.append(int(i.strip()))\n",
    "print(\"changed id length is: \", len(changed_ids), \" with \", changed_ids[2:8])\n",
    "\n",
    "train2015_05_28_changed = train2015_05_28[train2015_05_28.ncodpers.isin(changed_ids)]\n",
    "train2015_06_28_changed = train2015_06_28[train2015_06_28.ncodpers.isin(changed_ids)]\n",
    "print(train2015_05_28_changed.shape)\n",
    "print(train2015_06_28_changed.shape)\n",
    "\n",
    "# save them\n",
    "train2015_05_28_changed.to_csv(\"train2015_05_28_changed.csv\", index=False)\n",
    "train2015_06_28_changed.to_csv(\"train2015_06_28_changed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to find out those customers who changed services betweeen 2015-05-28 to 2015-06-28\n",
    "# to use this approach, I need to make sure their index are the same\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "\n",
    "changed_status_55 = []\n",
    "changed_status_56 = []\n",
    "\n",
    "same55 = []\n",
    "\n",
    "train_common_customers = list(train_common_customers)\n",
    "\n",
    "for id in range(len(train_common_customers)):\n",
    "    customer = train_common_customers[id]\n",
    "    #print(customer)\n",
    "    \n",
    "    all_2015_05 = may_data[may_data.index == customer]\n",
    "    all_2015_06 = june_data[june_data.index == customer]\n",
    "    #print(all_2015_05.shape[0])\n",
    "\n",
    "    # for services changed\n",
    "    for idx1, row1 in all_2015_05.iterrows():\n",
    "        for idx2, row2 in all_2015_06.iterrows():\n",
    "            tmp = [max(abs(int(x1) - int(x2)),0) for (x1, x2) in zip(row1, row2)]\n",
    "            if sum(tmp) == 0:\n",
    "                row1 = row1.tolist()\n",
    "                row1.append(idx1)\n",
    "                same55.append(row1)\n",
    "                \n",
    "#    try:\n",
    "#        assert_frame_equal(all_2015_05, all_2015_06)\n",
    "#    except:\n",
    "        #changed_status_55 = pd.concat([changed_status_55, all_2015_05])\n",
    "        #changed_status_56 = pd.concat([changed_status_56, all_2015_06])\n",
    "#        changed_status_55.append(customer)\n",
    "#        changed_status_56.append(customer)\n",
    "        \n",
    "#print(\"2015-05 total remaining: \", len(changed_status_55))\n",
    "#print(\"2015-06 total remaining: \", len(changed_status_56))\n",
    "\n",
    "print(\"2015-05 same list: \", len(same55))\n",
    "np.save(\"same55\", same55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1\n",
      "0  and  0\n",
      "0  and  0\n",
      "1  and  1\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "0  and  0\n",
      "same\n",
      "[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1048582]\n",
      "1048582  and  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "#np.save(\"changed_status_55\", changed_status_55)\n",
    "#np.save(\"changed_status_56\", changed_status_56)\n",
    "print(type(same55))\n",
    "#print(same55[3:10])\n",
    "# [15906, 15925, 15927, 15964, 15982, 16026, 16043, 16056] 1048581.0, 1048582.0, 1048583.0, 1048585.0, 1048584.0\n",
    "\n",
    "all_2015_05 = may_data[may_data.index == 1048582.0]\n",
    "all_2015_06 = june_data[june_data.index == 1048582.0]\n",
    "print(all_2015_05.shape[0])\n",
    "\n",
    "# for services changed\n",
    "for idx1, row1 in all_2015_05.iterrows():\n",
    "    #print(\"id 1 is: \", idx1, \"\\n\", row1)\n",
    "    for idx2, row2 in all_2015_06.iterrows():\n",
    "        #print(\"id2 is: \", idx2, \"\\n\", row2)\n",
    "        #tmp = [max(abs(int(x1) - int(x2)),0) for (x1, x2) in zip(row1, row2)]\n",
    "        [print(int(x1), \" and \", int(x2)) for (x1, x2) in zip(row1, row2)]\n",
    "        if sum(tmp) == 0:\n",
    "            row1 = row1.tolist()\n",
    "            row1.append(idx1)\n",
    "            same55.append(row1)\n",
    "            #print(row1)\n",
    "            #abc = row1.pop(-1)\n",
    "            #print(abc, \" and \", row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ind_aval_fin_ult1  ind_cco_fin_ult1  ind_cder_fin_ult1  \\\n",
      "34226                  0                 1                  0   \n",
      "\n",
      "       ind_cno_fin_ult1  ind_ctju_fin_ult1  ind_ctma_fin_ult1  \\\n",
      "34226                 0                  0                  0   \n",
      "\n",
      "       ind_ctop_fin_ult1  ind_ctpp_fin_ult1  ind_deco_fin_ult1  \\\n",
      "34226                  0                  0                  0   \n",
      "\n",
      "       ind_deme_fin_ult1       ...         ind_hip_fin_ult1  \\\n",
      "34226                  0       ...                        0   \n",
      "\n",
      "       ind_plan_fin_ult1  ind_pres_fin_ult1  ind_reca_fin_ult1  \\\n",
      "34226                  0                  0                  0   \n",
      "\n",
      "       ind_tjcr_fin_ult1  ind_valo_fin_ult1  ind_viv_fin_ult1  \\\n",
      "34226                  0                  0                 0   \n",
      "\n",
      "       ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  \n",
      "34226              0.0                0.0                0  \n",
      "\n",
      "[1 rows x 23 columns]\n",
      "(1, 47)\n"
     ]
    }
   ],
   "source": [
    "#print(train2015_05_28.iloc[:,24:].head(2))\n",
    "#print(train2015_05_28.head())\n",
    "print(train2015_05_28.loc[train2015_05_28.ncodpers == 1048576].iloc[:,24:])\n",
    "print(train2015_05_28.loc[train2015_05_28.ncodpers == 1061283].shape)\n",
    "#print(train2015_05_28.head().iloc[:,24:])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
