{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 47)\n",
      "(100, 47)\n",
      "(100, 47)\n",
      "(100, 23)\n",
      "Unique ones are:  (3354, 47)\n",
      "Unique ones are:  (3507, 47)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read in all files\n",
    "train2015_05_28 = pd.read_csv(\"../input/train2015_05_28_changed.csv\")\n",
    "train2015_06_28 = pd.read_csv(\"../input/train2015_06_28_changed.csv\")\n",
    "train2016_05_28 = pd.read_csv(\"../input/train2016_05_28.csv\")\n",
    "testX = pd.read_csv(\"../input/testX.csv\")\n",
    "\n",
    "print(train2015_05_28.shape)\n",
    "print(train2015_06_28.shape)\n",
    "print(train2016_05_28.shape)\n",
    "print(testX.shape)\n",
    "\n",
    "# the unique ones in either 2015-05-28 or 2015-06-28\n",
    "train2015_05_28_unique = pd.read_csv('../input/train2015_05_28_unique.csv')\n",
    "print(\"Unique ones are: \", train2015_05_28_unique.shape)\n",
    "\n",
    "train2015_06_28_unique = pd.read_csv('../input/train2015_06_28_unique.csv')\n",
    "print(\"Unique ones are: \", train2015_06_28_unique.shape)\n",
    "\n",
    "# read in changed id list\n",
    "#changed_ids = []\n",
    "#with open('changed_ids.txt', 'r') as f:\n",
    "#    for line in f:\n",
    "#        changed_ids.append(int(line.strip()))\n",
    "#print(\"changed list is: \", len(changed_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### only 22 products has data. Products 'ind_ahor_fin_ult1' un 'ind_aval_fin_ult1' have not been purchased.\n",
    "- so we need to drop these two columns\n",
    "- in addition, the date information should also be removed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ncodpers  age  ind_nuevo  antiguedad  indrel  indrel_1mes  tipodom  \\\n",
      "99   1065933   33        0.0        34.0     1.0            1      1.0   \n",
      "\n",
      "    cod_prov  ind_actividad_cliente          renta       ...         \\\n",
      "99      27.0                    1.0  178865.279517       ...          \n",
      "\n",
      "    ind_hip_fin_ult1  ind_plan_fin_ult1  ind_pres_fin_ult1  ind_reca_fin_ult1  \\\n",
      "99                 0                  0                  0                  0   \n",
      "\n",
      "    ind_tjcr_fin_ult1  ind_valo_fin_ult1  ind_viv_fin_ult1  ind_nomina_ult1  \\\n",
      "99                  0                  0                 0              1.0   \n",
      "\n",
      "    ind_nom_pens_ult1  ind_recibo_ult1  \n",
      "99                1.0                1  \n",
      "\n",
      "[1 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "train2015_05_28.drop(['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'fecha_dato', 'fecha_alta', 'ult_fec_cli_1t'], 1, inplace=True)\n",
    "train2015_06_28.drop(['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'fecha_dato', 'fecha_alta', 'ult_fec_cli_1t'], 1, inplace=True)\n",
    "train2016_05_28.drop(['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'fecha_dato', 'fecha_alta', 'ult_fec_cli_1t'], 1, inplace=True)\n",
    "print(train2015_05_28.shape)\n",
    "print(train2015_06_28.shape)\n",
    "print(train2016_05_28.shape)\n",
    "\n",
    "train2015_05_28_unique.drop(['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'fecha_dato', 'fecha_alta', 'ult_fec_cli_1t'], 1, inplace=True)\n",
    "train2015_06_28_unique.drop(['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'fecha_dato', 'fecha_alta', 'ult_fec_cli_1t'], 1, inplace=True)\n",
    "print(\"Unique ones are: \", train2015_05_28_unique.shape)\n",
    "print(\"Unique ones are: \", train2015_06_28_unique.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For padding\n",
    "- when compare two different months, some columns values are missing as they are unique to individual months\n",
    "- in order to do the comparison, the month with missing customers will have to pad everything in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding for 55 is:  (3507, 45)\n",
      "2015-05-28 only:  (100, 45)\n",
      "2015-06-28 only:  (100, 45)\n",
      "the entire list for 2015:  (6961, 45)\n"
     ]
    }
   ],
   "source": [
    "target_cols = ['ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1','ind_ctju_fin_ult1','ind_ctma_fin_ult1',\n",
    "               'ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_deme_fin_ult1','ind_dela_fin_ult1',\n",
    "               'ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1','ind_plan_fin_ult1','ind_pres_fin_ult1',\n",
    "               'ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1','ind_nomina_ult1',\n",
    "               'ind_nom_pens_ult1','ind_recibo_ult1']\n",
    "\n",
    "# for padding\n",
    "padding_for_55 = train2015_06_28_unique.copy()\n",
    "padding_for_55[target_cols] = [0] * 22\n",
    "\n",
    "padding_for_56 = train2015_05_28_unique.copy()\n",
    "padding_for_56[target_cols] = [0] * 22\n",
    "\n",
    "\n",
    "print(\"padding for 55 is: \", padding_for_55.shape)\n",
    "#print(train2015_06_28_unique[target_cols].iloc[1:2,:])\n",
    "#print(padding_for_55[target_cols].iloc[1:2,:])\n",
    "\n",
    "# compose the changed list for 2015-05-28\n",
    "#train55 = pd.concat([train2015_05_28_unique])\n",
    "train55 = pd.concat([train2015_05_28, train2015_05_28_unique, padding_for_55])\n",
    "print(\"2015-05-28 only: \", train55.shape)\n",
    "\n",
    "# compose the changed list for 2015-06-28\n",
    "train56 = pd.concat([train2015_06_28, train2015_06_28_unique, padding_for_56])\n",
    "#train56 = pd.concat([padding_for_56])\n",
    "print(\"2015-06-28 only: \", train56.shape)\n",
    "\n",
    "# changed list for all 2015\n",
    "trainX2015 = pd.concat([train2015_05_28, train2015_05_28_unique, train2015_06_28_unique])\n",
    "print(\"the entire list for 2015: \", trainX2015.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 45)\n",
      "[21, 19, 20, 19, 20, 19, 20, 2, 0, 2, 16, 21, 0, 21, 16, 0, 2, 16, 21, 19, 20, 21, 15, 21, 15, 16, 0, 10, 19, 20, 21, 19, 20, 21, 0, 2, 21, 10, 19, 20, 0, 2, 15, 21, 4, 10, 15, 19, 20, 20, 21, 21, 16, 19, 20, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "# now need to find out changed target in a single column list format\n",
    "\n",
    "trainY = []\n",
    "trainX = []\n",
    "\n",
    "for idx, row in train56.iterrows():\n",
    "    customer_id = row.ncodpers\n",
    "    row55 = train55[train55.ncodpers == customer_id]        \n",
    "    cur_target_list  = row[target_cols].values\n",
    "    prev_target_list = row55[target_cols].values[0]\n",
    "    row55.drop(['ncodpers'], 1, inplace=True)\n",
    "    row55 = row55.values[0]\n",
    "    #print(prev_target_list, \" and \", cur_target_list)\n",
    "\n",
    "    new_target_list =[max(abs(int(x1) - int(x2)), 0) for (x1, x2) in zip(cur_target_list, prev_target_list)]\n",
    "    \n",
    "    for ind, val in enumerate(new_target_list):\n",
    "        if val != 0:\n",
    "            trainX.append(row55)\n",
    "            trainY.append(ind)\n",
    "            \n",
    "print(len(trainY))\n",
    "print(len(trainX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(Counter(trainY))\n",
    "#with open('trainY.txt', 'w') as f:\n",
    "#    for i in trainY:\n",
    "#        f.write(\"%d\\n\" % i)\n",
    "\n",
    "#trainX = np.array(trainX)\n",
    "#trainY = np.array(trainY)\n",
    "print(trainY.shape)\n",
    "print(trainX.shape)\n",
    "print(trainX[0])\n",
    "\n",
    "#trainY.dump(\"trainY.dat\")\n",
    "#trainX.dump(\"trainX.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# now need to convert testX file\n",
    "testX = pd.read_csv(\"../input/testX.csv\")#, nrows=5)\n",
    "print(testX.shape)\n",
    "\n",
    "#testX[target_cols] = [0]*22\n",
    "testX.drop(['ncodpers', 'fecha_dato', 'fecha_alta', 'ult_fec_cli_1t'], 1, inplace=True)\n",
    "\n",
    "print(testX.shape)\n",
    "\n",
    "testData = []\n",
    "for idx, row in testX.iterrows():\n",
    "    row = row.tolist()\n",
    "    testData.append(row + [0]*22)\n",
    "    \n",
    "print(len(testData))\n",
    "\n",
    "testX = np.array(testData)\n",
    "print(testX.shape)\n",
    "#print(testX)\n",
    "\n",
    "#np.save(\"testX\", testX)\n",
    "#testX.dump(\"testX.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {'seed': 0,\n",
    "          'colsample_bytree': 0.7,\n",
    "          'silent': 1,\n",
    "          'subsample': 0.5,\n",
    "          'learning_rate': 0.1,\n",
    "          'objective': 'binary:logistic',\n",
    "          'max_depth': 10,\n",
    "          'min_child_weight': 100,\n",
    "          'booster': 'gbtree', \n",
    "          'eval_metric': 'mlogloss',\n",
    "         }\n",
    "\n",
    "#params = {'seed': 125,\n",
    "#          'colsample_bytree': 0.7,\n",
    "#          'silent': 1,\n",
    "#          'subsample': 0.7,\n",
    "#          'eta': 0.05,\n",
    "#          'objective': 'multi:softprob',\n",
    "#          'max_depth': 8,\n",
    "#          'min_child_weight': 1,\n",
    "#          'eval_metric': 'mlogloss',\n",
    "#          'num_class' : 22\n",
    "#         }\n",
    "\n",
    "num_rounds = 50\n",
    "\n",
    "trainX = xgb.DMatrix(trainX, label=trainY)\n",
    "testX = xgb.DMatrix(testX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
